{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   #importing tensorflow libraries\n",
    "import matplotlib.pyplot as plt  #importing matplotlib to plotting graphs\n",
    "from tensorflow import keras   #importing keras for neural network\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.optimizers import RMSprop, Adam  \n",
    "from keras.models import Sequential  # To create a plain stack of layers where each layer has one input tensor and one output tensor\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.load_img('C:/Users/Abhay/Final_Capstone/Train/1-HAPPY/1.jpg'))  #loading the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training, validation, testing dataset, and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)       #initiate class for training \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)  #initiate class for validation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  #initiate class for testing\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "        'C:/Users/Abhay/Final_Capstone/Train',  # this is the input directory\n",
    "        target_size=(100, 100),  # all images will be resized to 148x148 . Since we cannot give multiple size images to neural network, we resize the images\n",
    "        batch_size=100,           # the neural network will train up in batches of 2\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data, with images being resized to 148x148,trained in batches of 2 with binary labels.\n",
    "validation_data = validation_datagen.flow_from_directory(\n",
    "        'C:/Users/Abhay/Final_Capstone/Validation',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=10,\n",
    "        class_mode='binary')\n",
    "# this is a similar generator, for test data, with images being resized to 148x148,trained in batches of 2 with binary labels.\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "        'C:/Users/Abhay/Final_Capstone/Test',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=10,\n",
    "        class_mode='binary')\n",
    "train_data.class_indices # cars are labeled as 0 and not cars are labeled as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (48, 48, 3)   \n",
    "\n",
    "model_aug = Sequential() # Establishing networks as sequential\n",
    "model_aug.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE)) #add convolution layer with 32 filters\n",
    "model_aug.add(Activation('relu')) \n",
    "model_aug.add(Conv2D(32, (3, 3))) #add convolution layer with 32 filters\n",
    "model_aug.add(Activation('relu')) # add activation function as relu\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(BatchNormalization())\n",
    "\n",
    "model_aug.add(Conv2D(64, (3, 3))) #add convolution layer with 64 filters\n",
    "model_aug.add(Activation('relu')) # add activation function as relu \n",
    "model_aug.add(Conv2D(64, (3, 3))) #add convolution layer with 64 filters\n",
    "model_aug.add(Activation('relu')) # add activation function as relu\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(BatchNormalization())\n",
    "\n",
    "model_aug.add(Conv2D(128, (3, 3))) #add convolution layer with 128 filters\n",
    "model_aug.add(Activation('relu')) # add activation function as relu\n",
    "model_aug.add(Conv2D(128, (3, 3))) #add convolution layer with 128 filters\n",
    "model_aug.add(Activation('relu')) # add activation function as relu\n",
    "model_aug.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_aug.add(BatchNormalization())\n",
    "\n",
    "model_aug.add(Flatten())\n",
    "model_aug.add(Dense(128)) #add dense layer with 128 nodes\n",
    "model_aug.add(Activation('relu')) # add activation function as relu\n",
    "model_aug.add(Dropout(0.25))\n",
    "model_aug.add(Dense(7)) #add dense layer with 1 node\n",
    "model_aug.add(Activation('softmax')) # add activation function as sigmoid as it is better suited for binary outcomes\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model_aug.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "print(model_aug.summary())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aug=model_aug.fit_generator(      #Fitting the model\n",
    "        train_data,\n",
    "        epochs=2,\n",
    "        validation_data=validation_data,\n",
    "        )                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model_aug.evaluate(test_data) # Creating the evalutaion variable for x_test and y_test_cat\n",
    "print('Test Accuracy: {}'.format(evaluation[1])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting loss function with training set and validaton set\n",
    "plt.subplot(2, 2, 1) # First plot of the two plots\n",
    "plt.plot(history_aug.history['loss'], label='Loss') # First input variable for line graph(loss)\n",
    "plt.plot(history_aug.history['val_loss'], label='val_Loss') # second input variable for line graph(val_loss)\n",
    "plt.legend()\n",
    "plt.title('Loss evolution')\n",
    "\n",
    "\n",
    "#Plotting accuracy with training and validation set\n",
    "plt.subplot(2, 2, 2) \n",
    "plt.plot(history_aug.history['accuracy'], label='accuracy') # First input variable for line graph(accuracy)\n",
    "plt.plot(history_aug.history['val_accuracy'], label='val_accuracy') # second input variable for line graph(val_accuracy)\n",
    "plt.legend()\n",
    "plt.title('Accuracy evolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.save('new_model.h5')  # Saving the model\n",
    "new_model= tf.keras.models.load_model('new_model.h5')  # Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion detection on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread('C:/Users/Abhay/images.jpg')  # Taking a smaple image\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Converting it to RGB from BRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = DeepFace.analyze(img)   # Predicting the emotion\n",
    "Prediction['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # Conveting image into gray scale for HaarCascade\n",
    "gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces= faceCascade.detectMultiScale(gray,1.1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in faces:      # Plotting a rectangle aroung the face\n",
    "    cv2.rectangle(img, (x,y), (y+w, y+h), (0,225,0), 2)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))    # Ploting the face in RGB with rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implimenting it on the live feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(1)       \n",
    "# Checking if webcam is opened properly\n",
    "if not cap.isOpened():    \n",
    "    cap=cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "while True:\n",
    "    # Reading a single image from the video\n",
    "    ret,frame= cap.read()\n",
    "    result= DeepFace.analyze(frame,actions=['emotion'])\n",
    "    # Convert the image into gray scale \n",
    "    gray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    faces= faceCascade.detectMultiScale(gray, 1.1,4)\n",
    "    \n",
    "    # Draw rectangle around faces\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "    font= cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #Add the text\n",
    "    cv2.putText(frame,\n",
    "               result['dominant_emotion'],\n",
    "               (50,50),\n",
    "               font,3,\n",
    "               (0,0,255),\n",
    "               2,\n",
    "               cv2.LINE_4)\n",
    "    cv2.imshow('Orignal video', frame)\n",
    "    \n",
    "    if cv2.waitKey(2) & 0xff == ord ('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
